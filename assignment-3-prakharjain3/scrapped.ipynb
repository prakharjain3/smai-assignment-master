{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, n_inputs, activation_function):\n",
    "        self.n_inputs = n_inputs\n",
    "        self.activation_function = activation_function\n",
    "        self.weights = np.random.randn(n_inputs)\n",
    "        self.bias = np.random.randn()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.activation_function.forward(np.dot(x, self.weights) + self.bias)\n",
    "    \n",
    "    def backward(self, x, error):\n",
    "        return self.activation_function.backward(np.dot(x, self.weights) + self.bias) * error\n",
    "    \n",
    "    def update(self, x, error, learning_rate):\n",
    "        self.weights -= learning_rate * np.dot(x, error)\n",
    "        self.bias -= learning_rate * error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.array([1, 2, 3])\n",
    "x2 = np.array([4, 5, 6])\n",
    "x3 = np.array([7, 8, 9])\n",
    "\n",
    "# activation_function = [Sigmoid(), Tanh(), ReLU()]\n",
    "\n",
    "# for i in range(len(activation_function)):\n",
    "#     print(activation_function[i].activation(x1))\n",
    "#     print(activation_function[i].activation_derivative(x1))\n",
    "#     print(activation_function[i].activation(x2))\n",
    "#     print(activation_function[i].activation_derivative(x2))\n",
    "#     print(activation_function[i].activation(x3))\n",
    "#     print(activation_function[i].activation_derivative(x3))\n",
    "\n",
    "# sanity checks\n",
    "inputs = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "np.tanh(inputs)\n",
    "\n",
    "# for forward propagation\n",
    "m = 400\n",
    "d = 3\n",
    "\n",
    "no_of_neurons = 6\n",
    "\n",
    "X = np.random.randn(m, d)\n",
    "print(X[:2])\n",
    "weights = np.random.randn(d, no_of_neurons)\n",
    "print(weights[:2])\n",
    "\n",
    "bias = np.zeros((1, no_of_neurons))\n",
    "\n",
    "print(np.dot(X, weights).shape)\n",
    "\n",
    "print(np.dot(X, weights)[:2] + bias[:2])\n",
    "\n",
    "# for forward propagation\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
